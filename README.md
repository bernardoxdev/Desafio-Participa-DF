# 1¬∫ Hackathon em Controle Social: Desafio Participa DF
<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->
[![All Contributors](https://img.shields.io/badge/all_contributors-1-orange.svg?style=flat-square)](#contributors-)
<!-- ALL-CONTRIBUTORS-BADGE:END -->

<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->

[![All Contributors](https://img.shields.io/badge/all_contributors-0-orange.svg?style=flat-square)](#contributors-)

<!-- ALL-CONTRIBUTORS-BADGE:END -->

## Autores

- https://github.com/bernardoxdev [IA e Web]
- https://github.com/Qaddish [Web]

## O desafio: Desenvolver um modelo capaz de identificar automaticamente pedidos p√∫blicos que contenham dados pessoais.

Foi disponibilizado um modelo dos dados que est√° dispon√≠vel dentro de `backend/data/amostra_data.xlsx`

# Nossa solu√ß√£o:

    Para resolver o problema primeiro precisamos entender o que √© um "dado pessoal" de acordo com a LGPD, dados pessoais s√£o dados como:

- Nome de pessoas
- Email
- Telefone
- CPF / RG
- CNH
- T√≠tulo de Eleitor
- OAB
- N√∫mero de processo SEI
- N√∫mero de ocorr√™ncia policial
- Protocolo LAI
- N√∫mero de contrato
- N√∫mero de inscri√ß√£o de consumo
- N√∫mero de matr√≠cula funcional
- Dados jur√≠dicos e criminais

  Iremos utilizar como camadas da solu√ß√£o h√≠brida o seguinte:

```
Texto
 ‚îú‚îÄ‚îÄ Regex (CPF, email, telefone, processo)
 ‚îú‚îÄ‚îÄ Brutils (Dados brasileiros geral	)
 ‚îú‚îÄ‚îÄ NER (nomes, locais, organiza√ß√µes)
 ‚îú‚îÄ‚îÄ Classificador de contexto (sa√∫de, jur√≠dico, crian√ßa)
 ‚îî‚îÄ‚îÄ Agregador de risco (LGPD score)
```

    Inicialmente o sistema cria um modelo para classificar o texto com base em t√©cnicas de`TfidfVectorizer` e `Logistic Regression`, ele est√° sendo treinado a partir de datasets gerados por LLMs (Grandes Modelos de Linguagem) e dados tratados por pipelines de REGEX e NER.

Como funciona a pipeline de NLP:

```
Texto Cru -> TF - IDF (Vetoriza√ß√£o) -> Regess√£o Log√≠stica (Classifica√ß√£o)
```

M√©tricas usadas:

```
TfidfVectorizer(
	ngram_range=(1, 1),
	max_feature=3000,
	min_df=3,
	max_df=0.85,
	sublinear_tf=True
)
```

    No TF-IDF estamos utilizando apenas unigramas (uma palavra), limitamos a um range de 3000 palavras, ignoramos palavras que aparecem em menos de 3 documentos, removemos  stopwords e evitamos palavras repetidas dominem o modelo com o`TF = 1 + log(TF).`

```
LogisticRegression(
	C=0.3,
	class_weight="balaced",
	max_iter=1000
)
```

    Na regress√£o log√≠stica fazemos com que se tenha uma forte regulariza√ß√£o (0.3) como nosso texto possui muito ru√≠do, deixamos o pr√≥prio programa ajustar o peso das classes (PII << NON_PIII [ou vice-versa)) e garantimos a converg√™ncia.

```
StratifiedKFold(
	n_splits=5,
	shuffle=True,
	random_state=42
)
```

    Divide o dataset em 5 folds, treina e teste 5 vezes, com cada fold mantendo a propora√ß√£o de classes.

    Alguns conceitos importantes voltados a Regress√£o Log√≠stica s√£o a "regulariza√ß√£o" e o "max_iter garantir converg√™ncia". Primeiro precisamos entender o que a regress√£o log√≠stica em L2 tenta minimizar:`Erro + J + Complexidade`

- Erro -> Criar previs√µes
- Complexidade -> Pesos muito grandes

L2: \\[L_2 = \sum_{i} w_i^2\\]

    Resumindo: Penalidade grande a pesos grandes e modelo mais suave a pesos pequenos

    A regulariza√ß√£o matematicamente falando √©`C = 1 / J`. Agora qual a diferen√ßa entre L1 e L2 -> L1 zera os pesos e L2 diminui os pesos (sele√ß√£o x generaliza√ß√£o). O max_iter gera tempo para a regulariza√ß√£o agir e gradiente estabilizar.

    Ap√≥s os contextos serem gerados √© passado para an√°lise se um documento √© PII ou NON_PII, as m√©tricas e rac√≠cionio s√£o os mesmos do primeiro modelo. Com isso, √© passado para an√°lise de o que est√° contido e o mascaramento do texto. Antes vamos passar pelos n√∫meros dos modelos:

- Conext: (TR) 200 -> (TS) 5

|              | Precision | Recall | F1-Score | Support |
| ------------ | --------- | ------ | -------- | ------- |
| CHILD        | 1.0       | 1.0    | 1.0      | 5       |
| FINANCIAL    | 0.83      | 1.00   | 0.93     | 5       |
| HEALTH       | 1.00      | 1.00   | 1.00     | 5       |
| IDENTITY     | 1.00      | 0.80   | 0.89     | 5       |
| LEGAL        | 1.00      | 1.00   | 1.00     | 5       |
| ---          | ---       | ---    | ---      | ---     |
| Accuracy     | ---       | ---    | 0.96     | 25      |
| Macro AVG    | 0.97      | 0.96   | 0.96     | 25      |
| Weigthed AVG | 0.97      | 0.96   | 0.96     | 25      |

Accuracy M√©dia: 0.96

- Classification: (TR) 625 -> (TS) 20

|              | Precision | Recall | F1-Score | Support |
| ------------ | --------- | ------ | -------- | ------- |
| NON_PII      | 0.58      | 0.58   | 0.58     | 19      |
| PII          | 0.60      | 0.60   | 0.60     | 20      |
| ---          | ---       | ---    | ---      | ---     |
| Accuracy     | ---       | ---    | 0.59     | 39      |
| Macro AVG    | 0.59      | 0.59   | 0.59     | 39      |
| Weigthed AVG | 0.59      | 0.59   | 0.59     | 39      |

Accuracy M√©dia: 0.59

    Como existem outros 3 classificadores antes do modelo, sua accuracy de 0.59 n√£o vai ser t√£o prejudicial ao projeto. Agora vamos falar dos nossos outros 3 classificadores e do mascaramento do texto.

    As an√°lises que temos s√£o: REGEX, Brutils, Spacy. Com cada uma completando a outra em seus pontos fracos:

- Regex:
  - Pontos fortes: Extremamente r√°pido; Determin√≠stico; N√£o depende de modelo ou treinamento; F√°cil de auditar;
  - Pontos fracos: Alta taxa de falsos positivos; N√£o entende contexto; N√£o v√°lida semanticamente;
- Brutils:
  - Pontos fortes: Especializado em documentos reais do Brasil; Valida√ß√£o por d√≠gito verificador; Reduz falsos positivos;
  - Pontos fracos: Recall baixo; N√£o detecta contexto; Falha em textos informais ou com erros;
- Spacy:
  - Pontos fortes: Detecta nome de pessoa sem padr√£o fixo; Funciona mesmo sem documenta√ß√£o expli√≠cita;
  - Pontos fracos: Falsos positivos frequentes; Custo computacional elevado; Modelo n√£o treinado especificamente para LGPD
- Resumo:

| T√©cnica | Melhor para                | Falha em               |
| -------- | -------------------------- | ---------------------- |
| Regex    | Padr√µes fixos             | Contexto e Significado |
| Brutils  | Documentos reais           | Texto informal         |
| Spacy    | Nomes e PII impl√≠cita     | Ambiguidade            |
| Modelo   | Inten√ß√£o¬† e Significado | Determinismo           |

    J√° quando vamos falar sobre o mascaramento do texto estamos falando do nosso 1¬∞ modelo + REGEX + Spacy, os 3 fazem uma jun√ß√£o onde identificam as partes do texto que s√£o dados v√°lidos retornando mascarado. Por exemplo:

`"meu nome √© walter rodrigues cruz, no dia 25..." -> "meu nome √© [NOME], no dia 25..."`

# Rodar o programa:

## Criar o ambiente virtual (venv):

```
python3 -m venv venv
```

---

## Ativar o ambiente virtual:

### Linux:

```
source venv/bin/activate
```

### MacOs:

```
source venv/bin/activate
```

### Windows (Powershell):

```
venv\Scripts\Activate.ps1
```

### Windows (CMD):

```
venv\Scripts\activate

```

---

## Instalar depend√™ncias do projeto:

```
pip install --upgrade pip
pip install -r requirements.txt
```

---

## Baixar modelo de linguagem:

```
python3 -m spacy download pt_core_news_lg

```

---

## Executar o projeto:

```
python3 backend/main.py
```

---

## Abrir interface:

Para abrir a interface acesse o link: [http://localhost:5000](http://localhost:5000)

## Contributors ‚ú®

Thanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):
<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tbody>
    <tr>
      <td align="center" valign="top" width="14.28%"><a href="https://github.com/bernardoxdev"><img src="https://avatars.githubusercontent.com/u/69211132?v=4?s=100" width="100px;" alt="Bernardo de Castro"/><br /><sub><b>Bernardo de Castro</b></sub></a><br /><a href="https://github.com/bernardoxdev/Desafio-Participa-DF/commits?author=bernardoxdev" title="Code">üíª</a></td>
    </tr>
  </tbody>
  <tfoot>
    <tr>
      <td align="center" size="13px" colspan="7">
        <img src="https://raw.githubusercontent.com/all-contributors/all-contributors-cli/1b8533af435da9854653492b1327a23a4dbd0a10/assets/logo-small.svg">
          <a href="https://all-contributors.js.org/docs/en/bot/usage">Add your contributions</a>
        </img>
      </td>
    </tr>
  </tfoot>
</table>

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->

<!-- prettier-ignore-start -->

<!-- markdownlint-disable -->

<!-- markdownlint-restore -->

<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

This project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!
